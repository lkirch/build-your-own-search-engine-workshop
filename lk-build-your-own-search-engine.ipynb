{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708a3b6e-15b2-4125-96fa-27e414e760ce",
   "metadata": {},
   "source": [
    "# Build Your Own Search Engine Workshop\n",
    "\n",
    "https://github.com/alexeygrigorev/build-your-own-search-engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a74cc-edca-4f2c-ab0c-2e8f663c6800",
   "metadata": {},
   "source": [
    "### Bring in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a5da24d-6306-4849-8396-fcbaf20cb7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9419ad3b-167d-4b65-9f9d-66d98e02eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413537f7-dea3-45f6-af70-a98a1d646a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(documents, columns=['course', 'section', 'question', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43fccd-92be-4cec-97e2-c67d99df6e35",
   "metadata": {},
   "source": [
    "## Basics of Text Search\n",
    "\n",
    "* __Information Retrieval__ - The process of obtaining relevant information from large datasets based on user queries.\n",
    "* __Vector Spaces__ - A mathematical representation where text is converted into vectors (points in space) allowing for quantitative comparison.\n",
    "* __Bag of Words__ - A simple text representation model treating each document as a collection of words disregarding grammar and word order but keeping multiplicity.\n",
    "* __TF-IDF (Term Frequency-Inverse Document Frequency)__ - A statistical measure used to evaluate how important a word is to a document in a collection or corpus. It increases with the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e28a4f-63b8-45bd-a41c-bf3940da98c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>section</th>\n",
       "      <th>question</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - When will the course start?</td>\n",
       "      <td>The purpose of this document is to capture fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What are the prerequisites for this c...</td>\n",
       "      <td>GitHub - DataTalksClub data-engineering-zoomca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - Can I still join the course after the...</td>\n",
       "      <td>Yes, even if you don't register, you're still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - I have registered for the Data Engine...</td>\n",
       "      <td>You don't need it. You're accepted. You can al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-engineering-zoomcamp</td>\n",
       "      <td>General course-related questions</td>\n",
       "      <td>Course - What can I do before the course starts?</td>\n",
       "      <td>You can start by installing and setting up all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      course                           section  \\\n",
       "0  data-engineering-zoomcamp  General course-related questions   \n",
       "1  data-engineering-zoomcamp  General course-related questions   \n",
       "2  data-engineering-zoomcamp  General course-related questions   \n",
       "3  data-engineering-zoomcamp  General course-related questions   \n",
       "4  data-engineering-zoomcamp  General course-related questions   \n",
       "\n",
       "                                            question  \\\n",
       "0               Course - When will the course start?   \n",
       "1  Course - What are the prerequisites for this c...   \n",
       "2  Course - Can I still join the course after the...   \n",
       "3  Course - I have registered for the Data Engine...   \n",
       "4   Course - What can I do before the course starts?   \n",
       "\n",
       "                                                text  \n",
       "0  The purpose of this document is to capture fre...  \n",
       "1  GitHub - DataTalksClub data-engineering-zoomca...  \n",
       "2  Yes, even if you don't register, you're still ...  \n",
       "3  You don't need it. You're accepted. You can al...  \n",
       "4  You can start by installing and setting up all...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.course == 'data-engineering-zoomcamp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617eb663-75cd-4c39-afb8-25abba10c033",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c2f7b1-2815-4554-b4a6-554ed47e77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_example = [\n",
    "    \"January course details, register now\",\n",
    "    \"Course prerequisites listed in January catalog\",\n",
    "    \"Submit January course homework by end of month\",\n",
    "    \"Register for January course, no prerequisites\",\n",
    "    \"January course setup: Python and Google Cloud\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96416036-412b-4a40-8361-632cae979ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(docs_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec59faf-079f-4f0a-bf61-7e4c18f54571",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5cc6621-ed97-479b-a3a6-6ac6d7e9c89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>catalog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloud</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homework</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prerequisites</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>register</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>submit</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4\n",
       "catalog        0  1  0  0  0\n",
       "cloud          0  0  0  0  1\n",
       "course         1  1  1  1  1\n",
       "details        1  0  0  0  0\n",
       "end            0  0  1  0  0\n",
       "google         0  0  0  0  1\n",
       "homework       0  0  1  0  0\n",
       "january        1  1  1  1  1\n",
       "listed         0  1  0  0  0\n",
       "month          0  0  1  0  0\n",
       "prerequisites  0  1  0  1  0\n",
       "python         0  0  0  0  1\n",
       "register       1  0  0  1  0\n",
       "setup          0  0  0  0  1\n",
       "submit         0  0  1  0  0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs = pd.DataFrame(X.toarray(), columns=names).T\n",
    "df_docs.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2fb8d-23b3-4547-b62e-f0eaef4c400d",
   "metadata": {},
   "source": [
    "### Query-Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102b7af0-930a-4958-8257-f21290a7df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Do I need to know python to sign up for the January course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad070a4-ed31-4100-b10c-5bda8fdba6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = cv.transform([query])\n",
    "q.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e483d653-1e9c-4d12-a472-b186a893500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog': 0,\n",
       " 'cloud': 0,\n",
       " 'course': 1,\n",
       " 'details': 0,\n",
       " 'end': 0,\n",
       " 'google': 0,\n",
       " 'homework': 0,\n",
       " 'january': 1,\n",
       " 'listed': 0,\n",
       " 'month': 0,\n",
       " 'prerequisites': 0,\n",
       " 'python': 1,\n",
       " 'register': 0,\n",
       " 'setup': 0,\n",
       " 'submit': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dict = dict(zip(names, q.toarray()[0]))\n",
    "query_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f522f85-8ba2-4f1b-bc49-3f1d33447583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'catalog': 1,\n",
       " 'cloud': 0,\n",
       " 'course': 1,\n",
       " 'details': 0,\n",
       " 'end': 0,\n",
       " 'google': 0,\n",
       " 'homework': 0,\n",
       " 'january': 1,\n",
       " 'listed': 1,\n",
       " 'month': 0,\n",
       " 'prerequisites': 1,\n",
       " 'python': 0,\n",
       " 'register': 0,\n",
       " 'setup': 0,\n",
       " 'submit': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dict = dict(zip(names, X.toarray()[1]))\n",
    "doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a4c89-79c0-497a-8d35-0465595b4ec4",
   "metadata": {},
   "source": [
    "Compute the score of how close the words are to each other.  The more words in common, the better the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1717219f-fc1c-4521-b95d-09d847ea22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qd = pd.DataFrame([query_dict, doc_dict], index=['query', 'doc']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27da0635-56c0-47cd-bc74-0b5599f63a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_qd['query'] * df_qd['doc']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fcc27cc-ac23-4f57-845a-e6fd0e81078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dot(q.T).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f916b5-fe80-45a1-9fe6-a1e1d8f712d8",
   "metadata": {},
   "source": [
    "Using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d1027b-302a-45b0-933c-d144be5aa2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57735027],\n",
       "       [0.51639778],\n",
       "       [0.47140452],\n",
       "       [0.57735027],\n",
       "       [0.70710678]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ae46a9-5d3a-417b-8436-613fae209b05",
   "metadata": {},
   "source": [
    "### Vectorizing all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d05977-3ffd-4a1a-abb4-0f37c3c1acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['section', 'question', 'text']\n",
    "transformers = {}\n",
    "matrices = {}\n",
    "\n",
    "for field in fields:\n",
    "    cv = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "    X = cv.fit_transform(df[field])\n",
    "\n",
    "    transformers[field] = cv\n",
    "    matrices[field] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ee1301-9992-45ce-9ebd-b080b95327c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['001', '01', '02', ..., 'zones', 'zoom', 'zoomcamp'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers['text'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f534a0e4-0674-446a-8f25-b842c276bb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<948x2118 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 26463 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251beabf-9ddd-49c0-911b-8957b350b041",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b62f1820-00a2-4dd2-a997-f5521dc33f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just singned up. Is it too late to join the course?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f89d460-635d-4172-8153-a2ed71fad5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = transformers['text'].transform([query])\n",
    "score = cosine_similarity(matrices['text'], q).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14da471-3a0b-45ad-b114-44db89bb7016",
   "metadata": {},
   "source": [
    "Using only the data engineering course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c4d4277-5e11-4a9a-915d-7f1bdf36b781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3336047 , 0.        , 0.        , 0.1328874 , 0.        ,\n",
       "       0.        , 0.        , 0.12722114, 0.        , 0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df.course == 'data-engineering-zoomcamp').values\n",
    "score = score * mask\n",
    "score[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ad7c6e-a5a6-4f12-ba9d-aa7eb04863c2",
   "metadata": {},
   "source": [
    "Get the top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9186c38-19d5-4982-bceb-5a1ee3f46684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  15,  22,  27,  38, 287,   3,   7, 113,  11])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(-score)[:10]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26ea9eb6-d8dd-45fa-9f92-3f00be170418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3336047 , 0.23530268, 0.22668   , 0.1894954 , 0.16484429,\n",
       "       0.13921764, 0.1328874 , 0.12722114, 0.1207499 , 0.10830554])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "757e1192-db3f-4612-bbbc-d5a44363356c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      The purpose of this document is to capture fre...\n",
       "15     No, late submissions are not allowed. But if t...\n",
       "22     It's up to you which platform and environment ...\n",
       "27     You can do most of the course without a cloud....\n",
       "38     You will have two attempts for a project. If t...\n",
       "287    This error could result if you are using some ...\n",
       "3      You don't need it. You're accepted. You can al...\n",
       "7      Yes, we will keep all the materials after the ...\n",
       "113    In the join queries, if we mention the column ...\n",
       "11     No, you can only get a certificate if you fini...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[idx].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9b25a-a73c-4e92-96b6-a8f8956fce5b",
   "metadata": {},
   "source": [
    "### Search with all the fields and boosting + filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5880777e-9b65-4b23-83b0-b12799d973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 3.0}\n",
    "\n",
    "score = np.zeros(len(df))\n",
    "\n",
    "for f in fields:\n",
    "    b = boost.get(f, 1.0)\n",
    "    q = transformers[f].transform([query])\n",
    "    s = cosine_similarity(matrices[f], q).flatten()\n",
    "    score = score + b * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f44b406-2213-4997-ae14-d1abc1b480d0",
   "metadata": {},
   "source": [
    "Add filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9386137c-72a2-4dda-b4ce-477dd94c85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\n",
    "    'course': 'data-engineering-zoomcamp'\n",
    "}\n",
    "\n",
    "for field, value in filters.items():\n",
    "    mask = (df[field] == value).values\n",
    "    score = score * mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c46cf3-98ae-4c3d-9ec9-329c6ca9edad",
   "metadata": {},
   "source": [
    "Get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79657dca-fad1-4a09-b797-0e0b4b5bf340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What are the prerequisites for this course?',\n",
       "  'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'How can we contribute to the course?',\n",
       "  'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - how many Zoomcamps in a year?',\n",
       "  'text': \"There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\\nData-Engineering (Jan - Apr)\\nMLOps (May - Aug)\\nMachine Learning (Sep - Jan)\\nThere's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\\nThey follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Which playlist on YouTube should I refer to?',\n",
       "  'text': 'All the main videos are stored in the Main “DATA ENGINEERING” playlist (no year specified). The Github repository has also been updated to show each video with a thumbnail, that would bring you directly to the same playlist below.\\nBelow is the MAIN PLAYLIST’. And then you refer to the year specific playlist for additional videos for that year like for office hours videos etc. Also find this playlist pinned to the slack channel.\\nh\\nttps://youtube.com/playlist?list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&si=NspQhtZhZQs1B9F-'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\"},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
       "  'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.'},\n",
       " {'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       "  'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argsort(-score)[:10]\n",
    "results = df.iloc[idx]\n",
    "results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac15acfb-1bc8-41f5-89e5-4407f3265b05",
   "metadata": {},
   "source": [
    "### Creating a TextSearch Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "511b25fa-08ab-4a77-8621-39a103159caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSearch:\n",
    "\n",
    "    def __init__(self, text_fields):\n",
    "        self.text_fields = text_fields\n",
    "        self.matrices = {}\n",
    "        self.vectorizers = {}\n",
    "\n",
    "    def fit(self, records, vectorizer_params={}):\n",
    "        self.df = pd.DataFrame(records)\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            cv = TfidfVectorizer(**vectorizer_params)\n",
    "            X = cv.fit_transform(self.df[f])\n",
    "            self.matrices[f] = X\n",
    "            self.vectorizers[f] = cv\n",
    "\n",
    "    def search(self, query, n_results=10, boost={}, filters={}):\n",
    "        score = np.zeros(len(self.df))\n",
    "\n",
    "        for f in self.text_fields:\n",
    "            b = boost.get(f, 1.0)\n",
    "            q = self.vectorizers[f].transform([query])\n",
    "            s = cosine_similarity(self.matrices[f], q).flatten()\n",
    "            score = score + b * s\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            mask = (self.df[field] == value).values\n",
    "            score = score * mask\n",
    "\n",
    "        idx = np.argsort(-score)[:n_results]\n",
    "        results = self.df.iloc[idx]\n",
    "        return results.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "579655fd-4391-49b8-9611-0aebe2ad9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = TextSearch(text_fields=['section', 'question', 'text'])\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a907b63a-a0e5-4999-b58d-b08cded7da00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search(\n",
    "    query='I just singned up. Is it too late to join the course?',\n",
    "    n_results=5,\n",
    "    boost={'question': 3.0},\n",
    "    filters={'course': 'data-engineering-zoomcamp'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870d693-93f2-4d10-a62a-d233c07eb060",
   "metadata": {},
   "source": [
    "### Embeddings and Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a05e6-765a-4581-8cb3-4f7f1ade2e3b",
   "metadata": {},
   "source": [
    "### What are Embeddings?\n",
    "\n",
    "* __Conversion to Numbers:__ Embeddings transform different words, sentences and documents into dense vectors (arrays with numbers).\n",
    "* __Capturing Similarity:__ They ensure similar items have similar numerical vectors, illustrating their closeness in terms of characteristics.\n",
    "* __Dimensionality Reduction:__ Embeddings reduce complex characteristics into vectors.\n",
    "* __Use in Machine Learning:__ These numerical vectors are used in machine learning models for tasks such as recommendations, text analysis, and pattern recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e1694-9c99-4362-b74e-c8c158cd90bc",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "Singular Value Decomposition is the simplest way to turn Bag-of-Words representation into embeddings\n",
    "\n",
    "This way we still don't preserve the word order (because it wasn't in the Bag-of-Words representation) but we reduce dimensionality and capture synonyms.\n",
    "\n",
    "We won't go into mathematics, it's sufficient to know that SVD \"compresses\" our input vectors in such a way that as much as possible of the original information is retained.\n",
    "\n",
    "This compression is lossy compression - meaning that we won't be able to restore the 100% of the original vector, but the result is close enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf67363-18f5-41b3-ba29-a7e3fbdf651c",
   "metadata": {},
   "source": [
    "Using the vectorizer for the \"text\" field and turning it into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "785e4c6b-0a80-442d-9c0f-e934e2bc0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrices['text']\n",
    "cv = transformers['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6da090df-4ed0-46ec-8244-0f42de38bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=16)\n",
    "X_emb = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6485573-2453-4fac-9d77-9471e7e21f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08800394, -0.07499914, -0.10007778,  0.05213412,  0.05167484,\n",
       "       -0.06479282,  0.01659522,  0.04532509, -0.19195346,  0.31484917,\n",
       "        0.0085522 ,  0.02464149, -0.14065429, -0.05123718,  0.04516738,\n",
       "        0.06855395])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfad1389-38a0-4ae7-8524-cf9c0ab52b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'I just singned up. Is it too late to join the course?'\n",
    "\n",
    "Q = cv.transform([query])\n",
    "Q_emb = svd.transform(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8844c07b-2615-4c4d-9212-5f08c1f3f291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04353757, -0.03067384, -0.04388804,  0.01290717,  0.02522119,\n",
       "       -0.05426147,  0.00860718,  0.02990206, -0.11739753,  0.17261364,\n",
       "        0.01654237,  0.01877646, -0.09001967, -0.02531067,  0.02853095,\n",
       "        0.02702295])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de585743-5582-4654-b039-606daf10d528",
   "metadata": {},
   "source": [
    "Similarity between the the query and the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45c2a53d-9973-4cf7-998e-280c122951d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1121002924367441"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X_emb[0], Q_emb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7055809-a370-43e3-bb49-6574aff3840b",
   "metadata": {},
   "source": [
    "For all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09e5ab55-7d4e-430a-bba9-61c03272ef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       " \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\"]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d57f9e-91d2-4384-9b98-bd96ddbd100a",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization\n",
    "\n",
    "SVD creates values with negative numbers. It's difficult to interpet them.\n",
    "\n",
    "NMF (Non-Negative Matrix Factorization) is a similar concept, except for non-negative input matrices it produces non-negative results.\n",
    "\n",
    "We can interpret each of the columns (features) of the embeddings as different topic/concents and to what extent this document is about this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a38d574-5c53-40d9-847c-ca93d804d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.74228008e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.06612680e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e8cd1b9-f0da-4f26-8583-c995eb9ca2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00084157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1730521 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00073279,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "300534b6-c4e7-4b93-af06-e97b9c39b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.',\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "list(df.loc[idx].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0399cda-fa1b-41b7-b5ca-3ff0637ef42c",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "The problem with the previous two approaches is that they don't take into account the word order. They just treat all the words separately (that's why it's called \"Bag-of-Words\")\n",
    "\n",
    "BERT and other transformer models don't have this problem.\n",
    "\n",
    "Let's create embeddings with BERT. We will use the Hugging Face library for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b58061c2-eb50-4c90-8935-3ad327a64921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m939.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f82151f-5e98-426d-969e-44fdfc0c7acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff580ed2f8e1460c918c6f874f06e2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a57e0f1e96401b903194648a09f670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d75d49d51a44ca49d5092af5298466e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f97fb6aa1b34c43bea908a5e23168b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f6331e3cfb474f8db2dfa07b7fabb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e2021-d94a-45c1-b2c0-07edd9594007",
   "metadata": {},
   "source": [
    "* tokenizer - for tunring text into vectors\n",
    "* model - for compressing the text into embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfc6c2-8a64-4700-8959-53a92db173fb",
   "metadata": {},
   "source": [
    "Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d30f3e05-a6e3-4908-8483-ef82912ef99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2748,  1010,  2057,  2097,  2562,  2035,  1996,  4475,  2044,\n",
       "          1996,  2607, 12321,  1012,   102],\n",
       "        [  101,  2017,  2064,  3582,  1996,  2607,  2012,  2115,  2219,  6393,\n",
       "          2044,  2009, 12321,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3454b0-0567-4524-9aba-7e7074cf7249",
   "metadata": {},
   "source": [
    "Compute the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4ef888a-eb20-4968-981b-5cc750771bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416ad01-679c-4b7b-93cd-12b1d1cfb648",
   "metadata": {},
   "source": [
    "Compress the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e147684-8ade-4bf3-82f5-e07e5e19af52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9d054-8178-48ec-9429-11bc13d3289c",
   "metadata": {},
   "source": [
    "Convert to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4ca3da4-3968-4fdc-8fc9-612ff770da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_emb = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58a5a3-531e-4a12-80b9-55889701a5ef",
   "metadata": {},
   "source": [
    "Note that if use a GPU, first you need to move your tensors to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b67a2eb7-4678-425f-85cf-c554707b985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_cpu = sentence_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b11a2f-f0d9-4dad-96d4-4af6b27d586c",
   "metadata": {},
   "source": [
    "Create a function to compute in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7a7a5f0-62dd-4e80-a504-f1ed07a7ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "978601e1-507b-4540-b450-69bd348d0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd70ac82-abcd-455d-9562-43676bdc64b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14cb6abc0a340a394be1527a3d3d176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = df['text'].tolist()\n",
    "text_batches = make_batches(texts, 8)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in tqdm(text_batches):\n",
    "    encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        batch_embeddings = hidden_states.mean(dim=1)\n",
    "        batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "        all_embeddings.append(batch_embeddings_np)\n",
    "\n",
    "final_embeddings = np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ff094-d982-4d6d-88d3-a6cf0ed531a6",
   "metadata": {},
   "source": [
    "Create a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd985f6d-ed6a-4761-96de-18ed9dc7319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(texts, batch_size=8):\n",
    "    text_batches = make_batches(texts, 8)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(text_batches):\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f5dcefd-7be7-443c-b7e5-767fb10d75a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d63ea16bfe4b7290a1ebe33e0886b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_text = compute_embeddings(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b645c2d0-fa4f-43f1-9fa9-3ebc1c399458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for section...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39f60875d7a4b88a14415e3e25c4572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for question...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577904e18b2f4622a7e47bafca2a91ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebe163f99b54d748572e48871a8f05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = {}\n",
    "# fields = ['section', 'question', 'text']\n",
    "\n",
    "for f in fields:\n",
    "    print(f'computing embeddings for {f}...')\n",
    "    embeddings[f] = compute_embeddings(df[f].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa19b2a9-8121-40df-b7ae-a95d5fb0be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you want to store the data\n",
    "file = open('embeddings.bin', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(embeddings, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886bcce4-3054-4159-a5f8-9682b820180d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
